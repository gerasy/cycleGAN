{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-8f855b28-a1e2-4532-8bdc-047c760d0ffa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1613383383272,
    "source_hash": "e42b38a3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here only executting stuff. no functions or classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-48ed086d-0958-40c4-b631-01633394445b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1613383383277,
    "source_hash": "89766bc1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## um die models und functions hier nutzen zu kÃ¶nnen, muss man die datein als module importieren. \n",
    "## das geht auch wenn das notebeooks sind, ist aber deutlich einfacher, wenn es einfach .py dateien sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-055fa27a-321e-4804-bb74-bfbc900f3efe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4005,
    "execution_start": 1613557472059,
    "output_cleared": false,
    "source_hash": "7958d4a9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-78088d56-d67c-4d76-aaea-d95e5e806463",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## CycleGAN Maps \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00004-69591244-834e-497c-9fa0-2eb3d0f0c2dc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3615,
    "execution_start": 1613557491964,
    "output_cleared": false,
    "source_hash": "50790b38",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no SGE_TASK_ID set, choosing default model parameters \n",
      "the device ist at\n",
      "cuda\n",
      "should load models to cuda\n",
      "device == cuda -> False\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "#-*- coding:utf-8 -*-\n",
    "#$ -l cuda=1 # remove this line when no GPU is needed!\n",
    "#$ -q all.q # do not fill the qlogin queue\n",
    "#$ -cwd # start processes in current working directory\n",
    "#$ -V # provide environment variables to processes\n",
    "#$ -t 1-8 # start 8 instances: to train different models in parallel\n",
    "#Cluster settings, \n",
    "\n",
    "try:\n",
    "    model_param_id = int(os.environ['SGE_TASK_ID'])\n",
    "except:\n",
    "    print(\"no SGE_TASK_ID set, choosing default model parameters \")\n",
    "    model_param_id = 0 #param_train_cycle_list[0] should be default model params\n",
    "\n",
    "import importlib\n",
    "import models\n",
    "import functions \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "importlib.reload(models)\n",
    "importlib.reload(functions)\n",
    "import numpy as np\n",
    "#different import way for cluster\n",
    "'''\n",
    "import imp\n",
    "models = imp.load_source('models', './models.py')\n",
    "functions = imp.load_source('functions', './functions.py')\n",
    "'''\n",
    "\n",
    "# init CycleGAN\n",
    "genA2B = models.Generator(input_nc=3, output_nc=3, n_residual_blocks=9)\n",
    "genB2A = models.Generator(input_nc=3, output_nc=3, n_residual_blocks=9)\n",
    "discA  = models.Discriminator(input_nc=3)\n",
    "discB  = models.Discriminator(input_nc=3)\n",
    "classifier = models.Classifier().net\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "databaseName = \"cityscapes\"\n",
    "root_path_data = \"./data/\"+databaseName\n",
    "root_path_checkpoints = \"./checkpoints/\"+databaseName\n",
    "\n",
    "targetEpoch = 50\n",
    "saveAt = 1 #how often to store the model at training\n",
    "print(\"the device ist at\")\n",
    "print(device)\n",
    "\n",
    "if device == torch.device(\"cuda\"):\n",
    "    #debug\n",
    "    print(\"should load models to cuda\")\n",
    "    print(\"device == cuda -> \"+ str(device == \"cuda:0\"))\n",
    "    #model.load_state_dict(torch.load(\"{}/{} epoch{}\".format(path, name, epoch)))\n",
    "else:\n",
    "    #debug\n",
    "    print(\"should load models to cpu\")\n",
    "    print(\"device == cuda -> \"+ str(device == \"cuda:0\"))\n",
    "    #model.load_state_dict(torch.load(\"{}/{} epoch{}\".format(path, name, epoch),map_location=torch.device('cpu')))\n",
    "\n",
    "cycle  = models.CycleGAN(genA2B, genB2A, discA, discB, classifier, device, root_path_data, root_path_checkpoints)\n",
    "\n",
    "\n",
    "param_train1  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r9_advMSE_l10\", resnet_blocks=9, loss_adv=torch.nn.MSELoss(), lambdas=(10,0.5)) # default\n",
    "param_train2  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r9_advMSE_l5\" , resnet_blocks=9, loss_adv=torch.nn.MSELoss(), lambdas=(5,0.5))\n",
    "param_train3  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r9_advL1_l10\", resnet_blocks=9, loss_adv=torch.nn.L1Loss(), lambdas=(10,0.5))\n",
    "param_train4  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r9_advL1_l5\" , resnet_blocks=9, loss_adv=torch.nn.L1Loss(), lambdas=(5,0.5))\n",
    "param_train5  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r5_advMSE_l10\", resnet_blocks=5, loss_adv=torch.nn.MSELoss(), lambdas=(10,0.5))\n",
    "param_train6  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r5_advMSE_l5\" , resnet_blocks=5, loss_adv=torch.nn.MSELoss(), lambdas=(5,0.5))\n",
    "param_train7  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r5_advL1_l10\", resnet_blocks=5, loss_adv=torch.nn.L1Loss(), lambdas=(10,0.5))\n",
    "param_train8  = models.Param(channels = 3, epochs = targetEpoch, saveEpoch = saveAt, size= 256,  name =\"cycle_r5_advL1_l5\" , resnet_blocks=5, loss_adv=torch.nn.L1Loss(), lambdas=(5,0.5))\n",
    "param_train_cycle_list = [param_train1, param_train2, param_train3, param_train4, param_train5, param_train6, param_train7, param_train8]\n",
    "\n",
    "# paramter to load the background error verison. since this extension needed major changes in training/loaded training was done locally.\n",
    "param_back_err = models.Param(name =\"background_default\", epochs = 80)\n",
    "\n",
    "# paramters needed to call eval_testset() function\n",
    "param_eval_testset = models.Param(channels = 3, size= 256) \n",
    "\n",
    "# parameters used for training the classifier\n",
    "param_train_classifier = models.Param(channels = 3, epochs = targetEpoch, size = 256, name = \"classifier_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_train_cycle = param_train_cycle_list[model_param_id-1]\n",
    "cycle.train(param_train_cycle)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every model --TODO\n",
    "for paramItem in param_train_cycle_list:\n",
    "    #load model\n",
    "    cycle.load_cycle_nets(epoch = 50, model_name = paramItem.name)\n",
    "    print(device)\n",
    "    #generate for every test image some output image\n",
    "    cycle._create_evalset_paired(paramItem,subfolder=paramItem.name)\n",
    "    #calculate error with expected image\n",
    "\n",
    "#compare errors between models\n",
    "\n",
    "#run pix2pix ? and compare it with that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Error for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE? SSIM? FCN? \n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "losses= {}\n",
    "for paramItem in param_train_cycle_list:\n",
    "    source_domains = [\"A\", \"B\"]\n",
    "    subfolder = paramItem.name\n",
    "    losses[paramItem.name]={}\n",
    "    for source in source_domains:  \n",
    "        losses[paramItem.name][source]=[]\n",
    "        folder=root_path_data + \"/eval{}/{}/\".format(source,subfolder)\n",
    "        folderSize = int(len(os.listdir(folder)) / 3)\n",
    "        for i in range(0,folderSize):\n",
    "            gen=\"{}{}_generated.jpg\".format(folder, i)\n",
    "            exp=\"{}{}_expected.jpg\".format(folder, i)\n",
    "            gen=Image.open(gen)\n",
    "            exp=Image.open(exp)\n",
    "            loss=functions.calcMSE(gen,exp)\n",
    "            losses[paramItem.name][source].append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param:cycle_r9_advMSE_l10 \t source:A \t std:0.0147 \t sum:20.06 \t overall:37.00\n",
      "param:cycle_r9_advMSE_l10 \t source:B \t std:0.0187 \t sum:16.94 \t overall:37.00\n",
      "param:cycle_r9_advMSE_l5 \t source:A \t std:0.0143 \t sum:25.65 \t overall:47.33\n",
      "param:cycle_r9_advMSE_l5 \t source:B \t std:0.0219 \t sum:21.68 \t overall:47.33\n",
      "param:cycle_r9_advL1_l10 \t source:A \t std:0.0152 \t sum:24.43 \t overall:50.35\n",
      "param:cycle_r9_advL1_l10 \t source:B \t std:0.0246 \t sum:25.93 \t overall:50.35\n",
      "param:cycle_r9_advL1_l5 \t source:A \t std:0.0140 \t sum:23.72 \t overall:48.56\n",
      "param:cycle_r9_advL1_l5 \t source:B \t std:0.0244 \t sum:24.84 \t overall:48.56\n",
      "param:cycle_r5_advMSE_l10 \t source:A \t std:0.0146 \t sum:25.27 \t overall:50.48\n",
      "param:cycle_r5_advMSE_l10 \t source:B \t std:0.0231 \t sum:25.22 \t overall:50.48\n",
      "param:cycle_r5_advMSE_l5 \t source:A \t std:0.0137 \t sum:24.20 \t overall:45.66\n",
      "param:cycle_r5_advMSE_l5 \t source:B \t std:0.0224 \t sum:21.46 \t overall:45.66\n",
      "param:cycle_r5_advL1_l10 \t source:A \t std:0.0143 \t sum:24.65 \t overall:49.80\n",
      "param:cycle_r5_advL1_l10 \t source:B \t std:0.0212 \t sum:25.14 \t overall:49.80\n",
      "param:cycle_r5_advL1_l5 \t source:A \t std:0.0153 \t sum:24.82 \t overall:48.06\n",
      "param:cycle_r5_advL1_l5 \t source:B \t std:0.0235 \t sum:23.24 \t overall:48.06\n"
     ]
    }
   ],
   "source": [
    "for paramItem in param_train_cycle_list:\n",
    "    source_domains = [\"A\", \"B\"]\n",
    "    for source in source_domains:\n",
    "        summ = np.array(losses[paramItem.name][source]).sum()\n",
    "        std = np.std(losses[paramItem.name][source])\n",
    "        overall = np.array(losses[paramItem.name]['A']).sum() + np.array(losses[paramItem.name]['B']).sum()\n",
    "        print(\"param:{} \\t source:{} \\t std:{:.4f} \\t sum:{:.2f} \\t overall:{:.2f}\".format(paramItem.name,source,std,summ,overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param:cycle_r9_advMSE_l10 source:A std:0.031439 sum:67.284000 overall:151.08299999999997\n",
      "param:cycle_r9_advMSE_l10 source:B std:0.042867 sum:83.799000 overall:151.08299999999997\n",
      "param:cycle_r9_advMSE_l5 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r9_advMSE_l5 source:B std:0.042452 sum:80.809000 overall:148.739\n",
      "param:cycle_r9_advL1_l10 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r9_advL1_l10 source:B std:0.042452 sum:80.809000 overall:148.739\n",
      "param:cycle_r9_advL1_l5 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r9_advL1_l5 source:B std:0.042452 sum:80.809000 overall:148.739\n",
      "param:cycle_r5_advMSE_l10 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r5_advMSE_l10 source:B std:0.042452 sum:80.809000 overall:148.739\n",
      "param:cycle_r5_advMSE_l5 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r5_advMSE_l5 source:B std:0.042452 sum:80.809000 overall:148.739\n",
      "param:cycle_r5_advL1_l10 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r5_advL1_l10 source:B std:0.042452 sum:80.809000 overall:148.739\n",
      "param:cycle_r5_advL1_l5 source:A std:0.030743 sum:67.930000 overall:148.739\n",
      "param:cycle_r5_advL1_l5 source:B std:0.042452 sum:80.809000 overall:148.739\n"
     ]
    }
   ],
   "source": [
    "for paramItem in param_train_cycle_list:\n",
    "    source_domains = [\"A\", \"B\"]\n",
    "    for source in source_domains:\n",
    "        summ = np.array(losses[paramItem.name][source]).sum()\n",
    "        std = np.std(losses[paramItem.name][source])\n",
    "        overall = np.array(losses[paramItem.name]['A']).sum() + np.array(losses[paramItem.name]['B']).sum()\n",
    "        print(\"param:{} source:{} std:{:2f} sum:{:0f} overall:{}\".format(paramItem.name,source,std,summ,overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bla\n",
    "for paramItem in param_train_cycle_list:\n",
    "    print(type(paramItem.name))\n",
    "    print(type(\"hallo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param:cycle_r9_advMSE_l10\n",
      " source:A \n",
      " std:0.020727(-0.000401) \n",
      " sum:42.331000(-2.137000) \n",
      " overall:200.31400000000002(-7.328000)\n",
      "param:cycle_r9_advMSE_l10\n",
      " source:B \n",
      " std:0.027450(-0.000226) \n",
      " sum:157.983000(-5.191000) \n",
      " overall:200.31400000000002(-7.328000)\n",
      "param:cycle_r9_advMSE_l5\n",
      " source:A \n",
      " std:0.019033(0.000683) \n",
      " sum:41.606000(-0.273000) \n",
      " overall:198.77599999999998(-13.650000)\n",
      "param:cycle_r9_advMSE_l5\n",
      " source:B \n",
      " std:0.027498(-0.000500) \n",
      " sum:157.170000(-13.377000) \n",
      " overall:198.77599999999998(-13.650000)\n",
      "param:cycle_r9_advL1_l10\n",
      " source:A \n",
      " std:0.019033(-0.001891) \n",
      " sum:41.606000(-2.063000) \n",
      " overall:198.77599999999998(-2.637000)\n",
      "param:cycle_r9_advL1_l10\n",
      " source:B \n",
      " std:0.027498(0.000904) \n",
      " sum:157.170000(-0.574000) \n",
      " overall:198.77599999999998(-2.637000)\n",
      "param:cycle_r9_advL1_l5\n",
      " source:A \n",
      " std:0.018212(0.000460) \n",
      " sum:40.860000(-4.238000) \n",
      " overall:205.512(3.300000)\n",
      "param:cycle_r9_advL1_l5\n",
      " source:B \n",
      " std:0.027137(0.000597) \n",
      " sum:164.652000(7.538000) \n",
      " overall:205.512(3.300000)\n",
      "param:cycle_r5_advMSE_l10\n",
      " source:A \n",
      " std:0.017783(-0.005494) \n",
      " sum:41.123000(-4.608000) \n",
      " overall:198.801(-12.670000)\n",
      "param:cycle_r5_advMSE_l10\n",
      " source:B \n",
      " std:0.028439(0.000364) \n",
      " sum:157.678000(-8.062000) \n",
      " overall:198.801(-12.670000)\n",
      "param:cycle_r5_advMSE_l5\n",
      " source:A \n",
      " std:0.018145(-0.003214) \n",
      " sum:41.852000(-2.875000) \n",
      " overall:196.74(-9.123000)\n",
      "param:cycle_r5_advMSE_l5\n",
      " source:B \n",
      " std:0.025475(-0.002191) \n",
      " sum:154.888000(-6.248000) \n",
      " overall:196.74(-9.123000)\n",
      "param:cycle_r5_advL1_l10\n",
      " source:A \n",
      " std:0.019074(0.000314) \n",
      " sum:42.191000(-1.312000) \n",
      " overall:201.615(-9.781000)\n",
      "param:cycle_r5_advL1_l10\n",
      " source:B \n",
      " std:0.027110(0.000470) \n",
      " sum:159.424000(-8.469000) \n",
      " overall:201.615(-9.781000)\n",
      "param:cycle_r5_advL1_l5\n",
      " source:A \n",
      " std:0.019074(0.001283) \n",
      " sum:42.191000(0.315000) \n",
      " overall:201.615(1.945000)\n",
      "param:cycle_r5_advL1_l5\n",
      " source:B \n",
      " std:0.027110(0.000615) \n",
      " sum:159.424000(1.630000) \n",
      " overall:201.615(1.945000)\n"
     ]
    }
   ],
   "source": [
    "#calculate differences between 50 and 100\n",
    "losses50 = np.load(root_path_data+\"/pairedlosses50.npy\",allow_pickle=True).item()\n",
    "losses100 = np.load(root_path_data+\"/pairedlosses100.npy\",allow_pickle=True).item()\n",
    "for paramItem in param_train_cycle_list:\n",
    "    source_domains = [\"A\", \"B\"]\n",
    "    for source in source_domains:\n",
    "        summ50 = np.array(losses50[paramItem.name][source]).sum()\n",
    "        std50 = np.std(losses50[paramItem.name][source])\n",
    "        overall50 = np.array(losses50[paramItem.name]['A']).sum() + np.array(losses50[paramItem.name]['B']).sum()\n",
    "        summ100 = np.array(losses100[paramItem.name][source]).sum()\n",
    "        std100 = np.std(losses100[paramItem.name][source])\n",
    "        overall100 = np.array(losses100[paramItem.name]['A']).sum() + np.array(losses100[paramItem.name]['B']).sum()\n",
    "        diffstd = std100-std50\n",
    "        diffsumm= summ100-summ50\n",
    "        diffoverall= overall100-overall50\n",
    "        print(\"param:{}\\n source:{} \\n std:{:2f}({:2f}) \\n sum:{:0f}({:0f}) \\n overall:{}({:2f})\".format(paramItem.name,source,std100,diffstd,summ100,diffsumm,overall100,diffoverall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses50.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "bfdeedbb-9869-448c-a7f5-bad7097fc492",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}